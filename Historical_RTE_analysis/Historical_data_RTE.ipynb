{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Production history converter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims at gathering the data published semi-annually by RTE (.xlsx files in ./RTE_gross_data/) into a single Pandas DataFrame (.csv.xz) to allow further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules import\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filenames list generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 filenames generated between ./RTE_gross_data/ProductionGroupe_2011-semestre2.xlsx and ./RTE_gross_data/ProductionGroupe_2023-semestre2.xlsx\n"
     ]
    }
   ],
   "source": [
    "# As RTE files are splited by semester, using .5 to differentiate between the first semester (integers) and second semester (half-integer)\n",
    "history_start_year = 2011.5                                         # First set available\n",
    "history_end_year = 2023.5                                           # Last set available\n",
    "\n",
    "# Type of RTE data to cast in a global pandas dataframe\n",
    "history_files_folder = \"./RTE_gross_data/\"                          # Relative path\n",
    "history_file_type = \"ProductionGroupe\"                              # Common root in the name\n",
    "\n",
    "# Generation of the filenames' list\n",
    "filenames_list = []\n",
    "for semester in range(int(10*history_start_year), int(10*(history_end_year+0.5)), 5):\n",
    "    filename_year = str(int((semester/10)//1))\n",
    "    filename_semester = str(int(1+2*((semester/10)%1)))\n",
    "    filenames_list.append(history_files_folder+history_file_type+\"_\"+filename_year+\"-semestre\"+filename_semester+\".xlsx\")\n",
    "#end for\n",
    "\n",
    "print(len(filenames_list), \"filenames generated between\", filenames_list[0], \"and\", filenames_list[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Units' names extraction\n",
    "Browsing into each Excel file (costly step requiring 4 minutes to run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./RTE_gross_data/ProductionGroupe_2011-semestre2.xlsx\n",
      "148 noms ajoutés à la liste\n",
      "./RTE_gross_data/ProductionGroupe_2012-semestre1.xlsx\n",
      "2 noms ajoutés à la liste\n",
      "./RTE_gross_data/ProductionGroupe_2012-semestre2.xlsx\n",
      "1 noms ajoutés à la liste\n",
      "./RTE_gross_data/ProductionGroupe_2013-semestre1.xlsx\n",
      "0 noms ajoutés à la liste\n",
      "./RTE_gross_data/ProductionGroupe_2013-semestre2.xlsx\n",
      "0 noms ajoutés à la liste\n",
      "./RTE_gross_data/ProductionGroupe_2014-semestre1.xlsx\n",
      "81 noms ajoutés à la liste\n",
      "./RTE_gross_data/ProductionGroupe_2014-semestre2.xlsx\n",
      "0 noms ajoutés à la liste\n",
      "./RTE_gross_data/ProductionGroupe_2015-semestre1.xlsx\n",
      "0 noms ajoutés à la liste\n",
      "./RTE_gross_data/ProductionGroupe_2015-semestre2.xlsx\n",
      "0 noms ajoutés à la liste\n",
      "./RTE_gross_data/ProductionGroupe_2016-semestre1.xlsx\n",
      "4 noms ajoutés à la liste\n",
      "./RTE_gross_data/ProductionGroupe_2016-semestre2.xlsx\n",
      "0 noms ajoutés à la liste\n",
      "./RTE_gross_data/ProductionGroupe_2017-semestre1.xlsx\n",
      "0 noms ajoutés à la liste\n",
      "./RTE_gross_data/ProductionGroupe_2017-semestre2.xlsx\n",
      "1 noms ajoutés à la liste\n",
      "./RTE_gross_data/ProductionGroupe_2018-semestre1.xlsx\n",
      "1 noms ajoutés à la liste\n",
      "./RTE_gross_data/ProductionGroupe_2018-semestre2.xlsx\n",
      "0 noms ajoutés à la liste\n",
      "./RTE_gross_data/ProductionGroupe_2019-semestre1.xlsx\n",
      "0 noms ajoutés à la liste\n",
      "./RTE_gross_data/ProductionGroupe_2019-semestre2.xlsx\n",
      "2 noms ajoutés à la liste\n",
      "./RTE_gross_data/ProductionGroupe_2020-semestre1.xlsx\n",
      "0 noms ajoutés à la liste\n",
      "./RTE_gross_data/ProductionGroupe_2020-semestre2.xlsx\n",
      "0 noms ajoutés à la liste\n",
      "./RTE_gross_data/ProductionGroupe_2021-semestre1.xlsx\n",
      "0 noms ajoutés à la liste\n",
      "./RTE_gross_data/ProductionGroupe_2021-semestre2.xlsx\n",
      "2 noms ajoutés à la liste\n",
      "./RTE_gross_data/ProductionGroupe_2022-semestre1.xlsx\n",
      "2 noms ajoutés à la liste\n",
      "./RTE_gross_data/ProductionGroupe_2022-semestre2.xlsx\n",
      "0 noms ajoutés à la liste\n",
      "./RTE_gross_data/ProductionGroupe_2023-semestre1.xlsx\n",
      "7 noms ajoutés à la liste\n",
      "./RTE_gross_data/ProductionGroupe_2023-semestre2.xlsx\n",
      "4 noms ajoutés à la liste\n",
      "255 noms extraits\n"
     ]
    }
   ],
   "source": [
    "unit_names = []\n",
    "\n",
    "for filename in filenames_list:\n",
    "    # For each file in the list\n",
    "    print(filename)                                                 # Printing filename is optional but helps monitoring the process while running\n",
    "    df = pd.read_excel(filename, header=1)                          # Filtering the technologies written on the first line, technologies will be fetched later\n",
    "\n",
    "    i = 0                                                           # Initialization of the counter of new names\n",
    "    for name in df.columns:\n",
    "        # For each column in the current file\n",
    "        if name in unit_names:\n",
    "            # If the name is already known, skip to the next column (watch out for the poor duplicates with typographic deltas)\n",
    "            pass\n",
    "        else:\n",
    "            #print(name, \"ajouté à la liste\")\n",
    "            unit_names.append(name)\n",
    "            i+=1                                                    # Increments the counter\n",
    "        #end if\n",
    "    #end for\n",
    "        \n",
    "    print(i, \"noms ajoutés à la liste\")                             # Printing is optional but helps locating a possible error\n",
    "#end for\n",
    "            \n",
    "print(len(unit_names), \"noms extraits\")                             # As of 2023, 255 must be extracted\n",
    "#print(unit_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Units' names duplicates removal :\n",
    "As the gross list has some poor duplicates, it is required to build manually a dictionary to assign the correct values to each gross value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_dict = {}                                                      # Net units' names dictionary initialization\n",
    "\n",
    "for elt in unit_names:\n",
    "    # It is required to manually add lines if duplicates are found\n",
    "    elt2 = elt.upper()\n",
    "    elt3 = elt2.replace(\"-\",\" \")\n",
    "    elt4 = elt3.replace(\" (LE) \", \" \")\n",
    "    elt5 = elt4.replace(\" (LA) \", \" \")\n",
    "    elt6 = elt5.replace(\" ( SUR SEINE) \", \" \")\n",
    "    elt7 = elt6.replace(\" (L ) \", \" \")\n",
    "    elt8 = elt7.replace(\"_\", \" \")\n",
    "    elt9 = elt8.replace(\"'\", \" \")\n",
    "    elt10 = elt9.replace(\"COMBIGOLFE CCG\", \"COMBIGOLFE\")\n",
    "    elt11 = elt10.replace(\"DAMPIERRE EN BURLY\", \"DAMPIERRE\")\n",
    "    elt12 = elt11.replace(\" SUR SEINE \", \" \")\n",
    "    elt13 = elt12.replace(\"ST ALBAN ST MAURICE\", \"ST ALBAN\")\n",
    "    elt14 = elt13.replace(\"LUCY 3\", \"LUCY\")\n",
    "    elt15 = elt14.replace(\"ST LAURENT DES EAUX B\", \"ST LAURENT\")\n",
    "    elt16 = elt15.replace(\"AMFARD\", \"AMFARD \")\n",
    "    elt17 = elt16.replace(\"SPEM CCG\", \"SPEM\")\n",
    "    elt18 = elt17.replace(\"CYCOFOS PL1\", \"CYCOFOS\")\n",
    "    elt19 = elt18.replace(\"CHINON 1\", \"CHINON B 1\")\n",
    "    elt20 = elt19.replace(\"CHINON 2\", \"CHINON B 2\")\n",
    "    elt21 = elt20.replace(\"CHINON 3\", \"CHINON B 3\")\n",
    "    elt22 = elt21.replace(\"CHINON 4\", \"CHINON B 4\")\n",
    "    elt23 = elt22.replace(\"CHOOZ 1\", \"CHOOZ B 1\")\n",
    "    elt24 = elt23.replace(\"CHOOZ 2\", \"CHOOZ B 2\")\n",
    "    elt25 = elt24.replace(\"PORCHEVILLE 1\", \"PORCHEVILLE B 1\")\n",
    "    elt26 = elt25.replace(\"PORCHEVILLE 2\", \"PORCHEVILLE B 2\")\n",
    "    elt27 = elt26.replace(\"PORCHEVILLE 3\", \"PORCHEVILLE B 3\")\n",
    "    elt28 = elt27.replace(\"PORCHEVILLE 4\", \"PORCHEVILLE B 4\")\n",
    "    unit_dict.update({elt: elt28})\n",
    "#end for\n",
    "    \n",
    "# At that stage, a problem remains about DK6 plant: from 2011 to 2014, there is only DK6 1 and DK6 2. After 2014 and until 2016, there is a duplicate for...\n",
    "# ...each DK6 with two DK6-TG and two DK6-TV. After 2016.5, there is only four DK6 plants: two DK6-TG and two DK6-TV. There is also a question remaining open...\n",
    "# ...about Saint-Pierre dam that seems to be inserted twice in RTE statements.\n",
    "# A conservative option will be to discard later CYCOFOS and DK6 plants, whose yearly contribution is rather low, to ensure a good fusion of datas\n",
    "\n",
    "# Names not to include in the final DataFrame\n",
    "corrupted_names = [\"CYCOFOS\", \"CYCOFOS PL2\", \"DK6 1\", \"DK6 2\", \"DK6-TG1\", \"DK6-TG2\", \"DK6-TV1\", \"DK6-TV2\"]\n",
    "\n",
    "# Commented section but can prove itself useful: prints the units' names conversion dictionary\n",
    "#content_dict = []\n",
    "#for key in unit_dict.keys():\n",
    "#    if not unit_dict[key] in content_dict:\n",
    "#        content_dict.append(unit_dict[key])\n",
    "#    #end if\n",
    "##end for\n",
    "#        \n",
    "##print(unit_dict)        \n",
    "#content_dict.sort()\n",
    "#print(content_dict)\n",
    "#print(len(content_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenating data from semi-annual statements\n",
    "Once the list of unit names is cleared of duplicates, we can start gathering data by concatenating vertically semesters. Before that, it will be required to modify the names of columns according to the dictionary created above to ensure continuity.\n",
    "\n",
    "This step can prove quite long: anticipate 3-4 minutes duration for 2011 - 2023 concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./RTE_gross_data/ProductionGroupe_2011-semestre2.xlsx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CYCOFOS column dropped\n",
      "DK6 1 column dropped\n",
      "DK6 2 column dropped\n",
      "(456, 145)\n",
      "./RTE_gross_data/ProductionGroupe_2012-semestre1.xlsx\n",
      "CYCOFOS column dropped\n",
      "DK6 1 column dropped\n",
      "DK6 2 column dropped\n",
      "(4824, 147)\n",
      "./RTE_gross_data/ProductionGroupe_2012-semestre2.xlsx\n",
      "CYCOFOS column dropped\n",
      "DK6 1 column dropped\n",
      "DK6 2 column dropped\n",
      "(9240, 148)\n",
      "./RTE_gross_data/ProductionGroupe_2013-semestre1.xlsx\n",
      "CYCOFOS column dropped\n",
      "DK6 1 column dropped\n",
      "DK6 2 column dropped\n",
      "(13583, 148)\n",
      "./RTE_gross_data/ProductionGroupe_2013-semestre2.xlsx\n",
      "CYCOFOS column dropped\n",
      "DK6 1 column dropped\n",
      "DK6 2 column dropped\n",
      "(17981, 148)\n",
      "./RTE_gross_data/ProductionGroupe_2014-semestre1.xlsx\n",
      "CYCOFOS column dropped\n",
      "CYCOFOS PL2 column dropped\n",
      "DK6 1 column dropped\n",
      "DK6 2 column dropped\n",
      "DK6-TG1 column dropped\n",
      "DK6-TG2 column dropped\n",
      "DK6-TV1 column dropped\n",
      "DK6-TV2 column dropped\n",
      "(22325, 156)\n",
      "./RTE_gross_data/ProductionGroupe_2014-semestre2.xlsx\n",
      "CYCOFOS column dropped\n",
      "CYCOFOS PL2 column dropped\n",
      "DK6 1 column dropped\n",
      "DK6 2 column dropped\n",
      "DK6-TG1 column dropped\n",
      "DK6-TG2 column dropped\n",
      "DK6-TV1 column dropped\n",
      "DK6-TV2 column dropped\n",
      "(26741, 156)\n",
      "./RTE_gross_data/ProductionGroupe_2015-semestre1.xlsx\n",
      "CYCOFOS column dropped\n",
      "CYCOFOS PL2 column dropped\n",
      "DK6 1 column dropped\n",
      "DK6 2 column dropped\n",
      "DK6-TG1 column dropped\n",
      "DK6-TG2 column dropped\n",
      "DK6-TV1 column dropped\n",
      "DK6-TV2 column dropped\n",
      "(31085, 156)\n",
      "./RTE_gross_data/ProductionGroupe_2015-semestre2.xlsx\n",
      "CYCOFOS column dropped\n",
      "CYCOFOS PL2 column dropped\n",
      "DK6 1 column dropped\n",
      "DK6 2 column dropped\n",
      "DK6-TG1 column dropped\n",
      "DK6-TG2 column dropped\n",
      "DK6-TV1 column dropped\n",
      "DK6-TV2 column dropped\n",
      "(35501, 156)\n",
      "./RTE_gross_data/ProductionGroupe_2016-semestre1.xlsx\n",
      "CYCOFOS column dropped\n",
      "CYCOFOS PL2 column dropped\n",
      "DK6 1 column dropped\n",
      "DK6 2 column dropped\n",
      "DK6-TG1 column dropped\n",
      "DK6-TG2 column dropped\n",
      "DK6-TV1 column dropped\n",
      "DK6-TV2 column dropped\n",
      "(39869, 160)\n",
      "./RTE_gross_data/ProductionGroupe_2016-semestre2.xlsx\n",
      "CYCOFOS PL2 column dropped\n",
      "DK6-TG1 column dropped\n",
      "DK6-TG2 column dropped\n",
      "DK6-TV1 column dropped\n",
      "DK6-TV2 column dropped\n",
      "(44276, 160)\n",
      "./RTE_gross_data/ProductionGroupe_2017-semestre1.xlsx\n",
      "CYCOFOS PL2 column dropped\n",
      "DK6-TG1 column dropped\n",
      "DK6-TG2 column dropped\n",
      "DK6-TV1 column dropped\n",
      "DK6-TV2 column dropped\n",
      "(48619, 160)\n",
      "./RTE_gross_data/ProductionGroupe_2017-semestre2.xlsx\n",
      "CYCOFOS PL2 column dropped\n",
      "DK6-TG1 column dropped\n",
      "DK6-TG2 column dropped\n",
      "DK6-TV1 column dropped\n",
      "DK6-TV2 column dropped\n",
      "(53002, 161)\n",
      "./RTE_gross_data/ProductionGroupe_2018-semestre1.xlsx\n",
      "CYCOFOS PL2 column dropped\n",
      "DK6-TG1 column dropped\n",
      "DK6-TG2 column dropped\n",
      "DK6-TV1 column dropped\n",
      "DK6-TV2 column dropped\n",
      "(57297, 162)\n",
      "./RTE_gross_data/ProductionGroupe_2018-semestre2.xlsx\n",
      "CYCOFOS PL2 column dropped\n",
      "DK6-TG1 column dropped\n",
      "DK6-TG2 column dropped\n",
      "DK6-TV1 column dropped\n",
      "DK6-TV2 column dropped\n",
      "(61648, 162)\n",
      "./RTE_gross_data/ProductionGroupe_2019-semestre1.xlsx\n",
      "CYCOFOS PL2 column dropped\n",
      "DK6-TG1 column dropped\n",
      "DK6-TG2 column dropped\n",
      "DK6-TV1 column dropped\n",
      "DK6-TV2 column dropped\n",
      "(65991, 162)\n",
      "./RTE_gross_data/ProductionGroupe_2019-semestre2.xlsx\n",
      "CYCOFOS PL2 column dropped\n",
      "DK6-TG1 column dropped\n",
      "DK6-TG2 column dropped\n",
      "DK6-TV1 column dropped\n",
      "DK6-TV2 column dropped\n",
      "(70401, 164)\n",
      "./RTE_gross_data/ProductionGroupe_2020-semestre1.xlsx\n",
      "CYCOFOS PL2 column dropped\n",
      "DK6-TG1 column dropped\n",
      "DK6-TG2 column dropped\n",
      "DK6-TV1 column dropped\n",
      "DK6-TV2 column dropped\n",
      "(74748, 164)\n",
      "./RTE_gross_data/ProductionGroupe_2020-semestre2.xlsx\n",
      "CYCOFOS PL2 column dropped\n",
      "DK6-TG1 column dropped\n",
      "DK6-TG2 column dropped\n",
      "DK6-TV1 column dropped\n",
      "DK6-TV2 column dropped\n",
      "(79157, 164)\n",
      "./RTE_gross_data/ProductionGroupe_2021-semestre1.xlsx\n",
      "CYCOFOS PL2 column dropped\n",
      "DK6-TG1 column dropped\n",
      "DK6-TG2 column dropped\n",
      "DK6-TV1 column dropped\n",
      "DK6-TV2 column dropped\n",
      "(83480, 164)\n",
      "./RTE_gross_data/ProductionGroupe_2021-semestre2.xlsx\n",
      "CYCOFOS PL2 column dropped\n",
      "DK6-TG1 column dropped\n",
      "DK6-TG2 column dropped\n",
      "DK6-TV1 column dropped\n",
      "DK6-TV2 column dropped\n",
      "(87882, 166)\n",
      "./RTE_gross_data/ProductionGroupe_2022-semestre1.xlsx\n",
      "CYCOFOS PL2 column dropped\n",
      "DK6-TG1 column dropped\n",
      "DK6-TG2 column dropped\n",
      "DK6-TV1 column dropped\n",
      "DK6-TV2 column dropped\n",
      "(92144, 168)\n",
      "./RTE_gross_data/ProductionGroupe_2022-semestre2.xlsx\n",
      "CYCOFOS PL2 column dropped\n",
      "DK6-TG1 column dropped\n",
      "DK6-TG2 column dropped\n",
      "DK6-TV1 column dropped\n",
      "DK6-TV2 column dropped\n",
      "(96472, 168)\n",
      "./RTE_gross_data/ProductionGroupe_2023-semestre1.xlsx\n",
      "CYCOFOS PL2 column dropped\n",
      "DK6-TG1 column dropped\n",
      "DK6-TG2 column dropped\n",
      "DK6-TV1 column dropped\n",
      "DK6-TV2 column dropped\n",
      "(100813, 175)\n",
      "./RTE_gross_data/ProductionGroupe_2023-semestre2.xlsx\n",
      "CYCOFOS PL2 column dropped\n",
      "DK6-TG1 column dropped\n",
      "DK6-TG2 column dropped\n",
      "DK6-TV1 column dropped\n",
      "DK6-TV2 column dropped\n",
      "(105229, 179)\n"
     ]
    }
   ],
   "source": [
    "i = 0                                                               # Flag variable that turns off concatenation if null\n",
    "\n",
    "for filename in filenames_list:\n",
    "    print(filename)                                                 # Printing filename is optional but helps monitoring the process while running\n",
    "    df = pd.read_excel(filename, header=1)                          # Gross dataframe with original names including duplicates\n",
    "    #print(df)\n",
    "    #print(df.shape)\n",
    "\n",
    "    for corrupted_name in corrupted_names:                          # Remove the columns with corrupted names (default: CyCoFos and DK6 units)\n",
    "        if corrupted_name in df.columns:                            # Avoiding \"key not found in axis\" error\n",
    "            df = df.drop(columns=corrupted_name)                    # Remove the column if name is corrupted\n",
    "            print(corrupted_name, \"column dropped\")                 # Printing dropped columns is optional but helps monitoring the process while running\n",
    "\n",
    "    df = df.rename(columns=unit_dict)                               # Renaming the remaining columns according to the dictionary\n",
    "    #print(df)\n",
    "\n",
    "    if i==0:\n",
    "        # First dataframe to be extracted, initializes the global dataframe\n",
    "        global_df = df\n",
    "    else:\n",
    "        # Concatenate the current dataframe to the global one\n",
    "        global_df = pd.concat([global_df, df], sort=False, ignore_index=True)\n",
    "    #end if\n",
    "        \n",
    "    i += 1\n",
    "        \n",
    "    print(global_df.shape)                                          # Printing shape is optional but helps monitoring the process while running\n",
    "#end for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Units' technologies extraction\n",
    "As the source files have the technology as a first row, we skipped it during the previous step. Let's browse again the files to extract units' technologies and add it to the DataFrame.\n",
    "This step can prove quite long: anticipate 3-4 minutes duration for 2011 - 2023 technology extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./RTE_gross_data/ProductionGroupe_2011-semestre2.xlsx\n",
      "./RTE_gross_data/ProductionGroupe_2012-semestre1.xlsx\n",
      "./RTE_gross_data/ProductionGroupe_2012-semestre2.xlsx\n",
      "./RTE_gross_data/ProductionGroupe_2013-semestre1.xlsx\n",
      "./RTE_gross_data/ProductionGroupe_2013-semestre2.xlsx\n",
      "./RTE_gross_data/ProductionGroupe_2014-semestre1.xlsx\n",
      "./RTE_gross_data/ProductionGroupe_2014-semestre2.xlsx\n",
      "./RTE_gross_data/ProductionGroupe_2015-semestre1.xlsx\n",
      "./RTE_gross_data/ProductionGroupe_2015-semestre2.xlsx\n",
      "./RTE_gross_data/ProductionGroupe_2016-semestre1.xlsx\n",
      "./RTE_gross_data/ProductionGroupe_2016-semestre2.xlsx\n",
      "./RTE_gross_data/ProductionGroupe_2017-semestre1.xlsx\n",
      "./RTE_gross_data/ProductionGroupe_2017-semestre2.xlsx\n",
      "./RTE_gross_data/ProductionGroupe_2018-semestre1.xlsx\n",
      "./RTE_gross_data/ProductionGroupe_2018-semestre2.xlsx\n",
      "./RTE_gross_data/ProductionGroupe_2019-semestre1.xlsx\n",
      "./RTE_gross_data/ProductionGroupe_2019-semestre2.xlsx\n",
      "./RTE_gross_data/ProductionGroupe_2020-semestre1.xlsx\n",
      "./RTE_gross_data/ProductionGroupe_2020-semestre2.xlsx\n",
      "./RTE_gross_data/ProductionGroupe_2021-semestre1.xlsx\n",
      "./RTE_gross_data/ProductionGroupe_2021-semestre2.xlsx\n",
      "./RTE_gross_data/ProductionGroupe_2022-semestre1.xlsx\n",
      "./RTE_gross_data/ProductionGroupe_2022-semestre2.xlsx\n",
      "./RTE_gross_data/ProductionGroupe_2023-semestre1.xlsx\n",
      "./RTE_gross_data/ProductionGroupe_2023-semestre2.xlsx\n"
     ]
    }
   ],
   "source": [
    "techno_dict = {}                                                    # Units' technologies dictionary initialization\n",
    "\n",
    "for filename in filenames_list:\n",
    "    print(filename)\n",
    "    df = pd.read_excel(filename, nrows=1)                           # All the file can be skipped after the first row\n",
    "\n",
    "    # At that stage we have a DataFrame with technologies as header.\n",
    "    # As DataFrame cannot support multiple columns with the same name, columns were renamed automatically with \".x\" and x an increasing value.\n",
    "    # It is impossible to swap header and rows that easily, so lets extract the data into a proper dictionary\n",
    "\n",
    "    for key in df.columns:\n",
    "        # For each column of the current file\n",
    "        unit_name = str(df[key].values[0])                          # We keep only the first cell with the unit's name\n",
    "        techno_name = key.split(\".\")[0]                             # The technology name per se is located before the \".\", we keep only this part\n",
    "\n",
    "        #print(\"Clé :\", key)\n",
    "        #print(\"Unité :\", unit_name)\n",
    "        #print(\"Techno :\", techno_name)\n",
    "\n",
    "        corrected_name = unit_dict[unit_name]                       # As the name can change from one statements to another, using the name correction dictionary will prevent errors\n",
    "\n",
    "        # To avoid duplicates, we add the technology to the dictionary if and only if it's not already known or corrupted\n",
    "        if corrected_name in global_df.columns:\n",
    "            if corrected_name not in techno_dict.keys():\n",
    "                techno_dict.update({corrected_name : techno_name})\n",
    "                #print(corrected_name, \"added\")\n",
    "            #end if\n",
    "            else:\n",
    "                #print(corrected_name, \"rejected because duplicate\")\n",
    "                pass\n",
    "        else:\n",
    "            #print(unit_name, \"rejected, may be corrupted\")\n",
    "            pass\n",
    "        #end if\n",
    "    #end for\n",
    "#end for\n",
    "\n",
    "techno_dict['DATE'] = \"\"                                            # Modifies the \"DATE\" value from \"Unnamed: 0\" to \"\"\n",
    "\n",
    "#print(techno_dict)\n",
    "#print(len(techno_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gathering aditionnal unit's technology and capacity datas into two DataFrame lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting dictionary content to add the model for NPPs\n",
    "filename =  \"./NPP_France_models.xlsx\"\n",
    "df = pd.read_excel(filename, index_col=0, header=0)\n",
    "\n",
    "for unit in df.index.values:\n",
    "    # For each nuclear power plant name known in the current file\n",
    "    techno_dict.update({unit : df[\"NPP model\"][unit]})              # Updates the technology by adding the model of the nuclear reactor\n",
    "    pass\n",
    "#end for\n",
    "#print(techno_dict)\n",
    "\n",
    "# Extracting the capacity of each unit from another Excel file\n",
    "filename =  \"./Units_France_capacity.xlsx\"\n",
    "df = pd.read_excel(filename, index_col=0, header=0)\n",
    "\n",
    "capacity_dict = techno_dict.copy()                                  # Instanciates capacity_dict on the same keys than techno_dict\n",
    "for key in capacity_dict.keys():\n",
    "    # For each unit in the dictionary\n",
    "    if key != \"DATE\":\n",
    "        capacity_dict.update({key : df[\"Capacity (MW)\"][key]})      # Fetches the capacity in the .xlsx file and updates the dictionary\n",
    "    else:\n",
    "        pass\n",
    "    #end if\n",
    "#end for\n",
    "#print(capacity_dict)\n",
    "    \n",
    "\n",
    "\n",
    "# Convert the resulting technology and capacity dictionaries into a Pandas DataFrame\n",
    "df = pd.DataFrame(data=techno_dict, index=[\"Technology\"])           # DataFrame line with technologies (and model for nuclear power plants)\n",
    "df2 = pd.DataFrame(data=capacity_dict, index=[\"Capacity (MW)\"])     # DataFrame line with capacity (expressed in MW)\n",
    "\n",
    "# Adds the new row to the dataframe\n",
    "global_df_with_tech = pd.concat([global_df, df, df2], sort=False)   # Concatenates the two lines at the end of the global dataframe\n",
    "\n",
    "# To reorganise the rows to have technology and capacity lines just below the header, it is necessary to create an index list\n",
    "\n",
    "new_indexes = [\"Technology\", \"Capacity (MW)\"]                       # DataFrame will begin with those indexes\n",
    "for i in range(global_df_with_tech.shape[0]-2):\n",
    "    # For all other lines, we append their index at the end of the index list\n",
    "    new_indexes.append(i)\n",
    "#end for\n",
    "#print(new_indexes[:3], \"...\", new_indexes[-3:])                     # Optional print to validate the swap\n",
    "\n",
    "final_df = global_df_with_tech.reindex(new_indexes)                 # Swaping lines per se\n",
    "#print(final_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global DataFrame export\n",
    "This step can prove quite long: anticipate 1 minute duration for 2011 - 2023 export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"./Processed_data/dataframe_RTE.csv.xz\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
